{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate DataFrames for each branch\n",
    "branch_a_df = df1[df1['branch'] == 'A']\n",
    "branch_b_df = df1[df1['branch'] == 'B']\n",
    "branch_c_df = df1[df1['branch'] == 'C']\n",
    "\n",
    "# Aggregate data for branch A\n",
    "branch_a_agg = branch_a_df.groupby('date').agg({\n",
    "    'unit_price': 'mean',\n",
    "    'quantity': 'sum',\n",
    "    'rating': 'mean',\n",
    "    'day': 'first',\n",
    "    'month': 'first',\n",
    "    'year': 'first',\n",
    "    'gross_income': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Aggregate data for branch B\n",
    "branch_b_agg = branch_b_df.groupby('date').agg({\n",
    "    'unit_price': 'mean',\n",
    "    'quantity': 'sum',\n",
    "    'rating': 'mean',\n",
    "    'day': 'first',\n",
    "    'month': 'first',\n",
    "    'year': 'first',\n",
    "    'gross_income': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Aggregate data for branch C\n",
    "branch_c_agg = branch_c_df.groupby('date').agg({\n",
    "    'unit_price': 'mean',\n",
    "    'quantity': 'sum',\n",
    "    'rating': 'mean',\n",
    "    'day': 'first',\n",
    "    'month': 'first',\n",
    "    'year': 'first',\n",
    "    'gross_income': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Add branch identifier\n",
    "branch_a_agg['branch'] = 'A'\n",
    "branch_b_agg['branch'] = 'B'\n",
    "branch_c_agg['branch'] = 'C'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([branch_a_agg, branch_b_agg, branch_c_agg], ignore_index=True)\n",
    "\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "\n",
    "# Sort the dataset by the 'date' column\n",
    "combined_df = combined_df.sort_values(by='date').reset_index(drop=True)\n",
    "combined_df \n",
    "\n",
    "\n",
    "# Encoding Categorical Variables\n",
    "# One-hot encode the 'branch' column\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "branch_encoded = encoder.fit_transform(combined_df[['branch']])\n",
    "\n",
    "# Create a DataFrame with the one-hot encoded branch data\n",
    "branch_encoded_df = pd.DataFrame(branch_encoded, columns=encoder.get_feature_names_out(['branch']))\n",
    "\n",
    "# Concatenate the one-hot encoded columns to the original dataframe\n",
    "combined_df_encoded = pd.concat([combined_df.drop(columns=['branch']), branch_encoded_df], axis=1)\n",
    "combined_df_encoded\n",
    "\n",
    "\n",
    "#### Shift Lag and Rolling Lag Moving Average:\n",
    "Shift quantity and unit_price by 1 period to create lagged versions.\n",
    "# Create lagged versions of 'quantity' and 'unit_price'\n",
    "combined_df_encoded['quantity_lag1'] = combined_df_encoded['quantity'].shift(1)\n",
    "combined_df_encoded['unit_price_lag1'] = combined_df_encoded['unit_price'].shift(1)\n",
    "\n",
    "# Create rolling averages of 'quantity' and 'unit_price' with a window of 7\n",
    "combined_df_encoded['quantity_roll7'] = combined_df_encoded['quantity'].rolling(window=7).mean()\n",
    "combined_df_encoded['unit_price_roll7'] = combined_df_encoded['unit_price'].rolling(window=7).mean()\n",
    "combined_df_encoded\n",
    "\n",
    "\n",
    "# Step 2: Transform 'day' column into sine and cosine components\n",
    "combined_df_encoded['day_sin'] = np.sin(2 * np.pi * combined_df_encoded['day'] / 31)\n",
    "combined_df_encoded['day_cos'] = np.cos(2 * np.pi * combined_df_encoded['day'] / 31)\n",
    "combined_df_encoded\n",
    "\n",
    "\n",
    "# Calculate the number of rows before dropping NaN values\n",
    "rows_before = combined_df_encoded.shape[0]\n",
    "\n",
    "# Drop rows with NaN values\n",
    "combined_df_encoded_dropped = combined_df_encoded.dropna().reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of rows after dropping NaN values\n",
    "rows_after = combined_df_encoded_dropped.shape[0]\n",
    "\n",
    "# Number of rows lost\n",
    "rows_lost = rows_before - rows_after\n",
    "\n",
    "rows_before, rows_after, rows_lost\n",
    "\n",
    "\n",
    "# Drop rows with NaN values resulting from the lag and rolling operations\n",
    "combined_df_encoded = combined_df_encoded.dropna().reset_index(drop=True)\n",
    "combined_df_encoded"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
